# -*- coding: utf-8 -*-
"""MNIST Dataset .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ALzwwjyKmIs_MN5mfpcmxFBqHgysI8Gt
"""

# write a python progtram to display the meta data of mnist dataset in following manners:
#upload a colab folder
#mounting of drive
#with the help of token from kaggle

from google.colab import drive
drive.mount('/content/drive')

import kagglehub
path = kagglehub.dataset_download("hojjatk/mnist-dataset")

import os

print(f"Files in the dataset directory '{path}':")
for file_name in os.listdir(path):
    print(file_name)

import os
import pandas as pd

# Define full paths to the files
train_images_path = os.path.join(path, 'train-images.idx3-ubyte')
train_labels_path = os.path.join(path, 'train-labels.idx1-ubyte')
test_images_path = os.path.join(path, 't10k-images.idx3-ubyte')
test_labels_path = os.path.join(path, 't10k-labels.idx1-ubyte')

print('--- Loading Training Data ---')
train_images = load_mnist_idx(train_images_path)
train_labels = load_mnist_idx(train_labels_path)

print('\n--- Loading Test Data ---')
test_images = load_mnist_idx(test_images_path)
test_labels = load_mnist_idx(test_labels_path)

print('\n--- Metadata for Training Images ---')
print(f"Shape: {train_images.shape}")
print(f"Data Type: {train_images.dtype}")
print(f"Number of Samples: {train_images.shape[0]}")

print('\n--- Metadata for Training Labels ---')
print(f"Shape: {train_labels.shape}")
print(f"Data Type: {train_labels.dtype}")
print(f"Number of Samples: {train_labels.shape[0]}")
print("Label Distribution:")
print(pd.Series(train_labels).value_counts().sort_index())

print('\n--- Metadata for Test Images ---')
print(f"Shape: {test_images.shape}")
print(f"Data Type: {test_images.dtype}")
print(f"Number of Samples: {test_images.shape[0]}")

print('\n--- Metadata for Test Labels ---')
print(f"Shape: {test_labels.shape}")
print(f"Data Type: {test_labels.dtype}")
print(f"Number of Samples: {test_labels.shape[0]}")
print("Label Distribution:")
print(pd.Series(test_labels).value_counts().sort_index())

#DAY2: 21th January 2026(LAB-04)
#source: https://www.kaggle.com/code/ibrahimqasimi/mnist-digit-recognition-cnn-deep-learning

#Data handling and numerical computations
import numpy as np

# Load MNIST dataset from Keras
from tensorflow.keras.datasets import mnist

# Deep learning framework (TensorFlow & Keras)
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense

# Visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Evaluation metrics
from sklearn.metrics import confusion_matrix, classification_report

# ===============================
# Ignore Warnings
# ===============================
import warnings
warnings.filterwarnings('ignore')

colors = ["#280536", "#d10d6f"]

# Splitting into train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Display dataset shapes
print("Training data shape:", x_train.shape, y_train.shape)
print("Testing data shape:", x_test.shape, y_test.shape)

print("Training images shape:", x_train.shape)
print("Training labels shape:", y_train.shape)
print("Testing images shape:", x_test.shape)
print("Testing labels shape:", y_test.shape)

unique_classes = np.unique(y_train)
print("Unique labels:", unique_classes)
print("Number of classes:", len(unique_classes))

plt.figure(figsize=(6,4))
plt.hist(x_train.reshape(-1), bins=30, color="#280536", edgecolor="black")
plt.title("Pixel Intensity Distribution", fontsize=14, fontweight='bold')
plt.xlabel("Pixel Intensity (0-255)")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(10,4))
for i in range(10):
    plt.subplot(2,5,i+1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')
plt.suptitle("Sample Images from MNIST Dataset", fontsize=16, fontweight='bold')
plt.show()

plt.figure(figsize=(8,4))
sns.countplot(x=y_train, palette=colors)
plt.title("Class Distribution in Training Data", fontsize=14, fontweight='bold')
plt.xlabel("Digit Label")
plt.ylabel("Count")
plt.show()

# Define the CNN architecture
model = Sequential([
    # First Conv + Pool block
    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0.25),

    # Second Conv + Pool block
    Conv2D(64, kernel_size=(3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),
    Dropout(0.25),

    # Flatten + Dense layers
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),

    # Output Layer (10 classes for digits 0–9)
    Dense(10, activation='softmax')
])

# Compile the CNN model
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train the model with validation split
history = model.fit(
    x_train, y_train,
    batch_size=128,
    epochs=2,
    validation_split=0.1,
    verbose=1
)

# Check what metrics are stored in history
print("History keys:", history.history.keys())

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)

print(f"✅ Test Accuracy: {test_accuracy:.4f}")
print(f"✅ Test Loss: {test_loss:.4f}")

# Get predictions
y_pred_probs = model.predict(x_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot heatmap
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap=colors, cbar=False)
plt.title("Confusion Matrix", fontsize=14, fontweight="bold")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()
#instance
10000











